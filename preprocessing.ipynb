{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klyshko/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/klyshko/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lyrics_titles_AutoPump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = open('all_lyrics.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 Choppa 2 Choppa*</td>\n",
       "      <td>[Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30's</td>\n",
       "      <td>[Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70 Nigga</td>\n",
       "      <td>\\r\\n            Lyrics for this song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Aight</td>\n",
       "      <td>[Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>At the Door</td>\n",
       "      <td>[Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               title  \\\n",
       "0           0  1 Choppa 2 Choppa*   \n",
       "1           0                30's   \n",
       "2           0            70 Nigga   \n",
       "3           0               Aight   \n",
       "4           0         At the Door   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...  \n",
       "1  [Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...  \n",
       "2            \\r\\n            Lyrics for this song...  \n",
       "3  [Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...  \n",
       "4  [Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data.itertuples():\n",
    "    text = row.lyrics\n",
    "    all_lyrics.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro: Lil Pump]\n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro: Lil Pump]\n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Verse]          \n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro]\n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro: Rick Ross]\n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro]\n",
      "\n",
      "            Lyrics for this song have yet to be released. Please check back once the song has been released.\n",
      "\n",
      "          \n",
      "\n",
      "        [Intro]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_lyrics = open('all_lyrics.txt', 'r')\n",
    "for line in all_lyrics:\n",
    "    if line.startswith('  '):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "all_lyrics = open('all_lyrics.txt', 'r')\n",
    "for line in all_lyrics:\n",
    "    if line.startswith(' '):\n",
    "        line = line.lstrip()\n",
    "    line = line.lower()\n",
    "    if line.startswith('[chorus'):\n",
    "        lines.append('[chorus] \\n')\n",
    "    elif line.startswith('[verse'):\n",
    "        lines.append('[verse] \\n')\n",
    "    elif line.startswith('[hook'):\n",
    "        lines.append('[hook] \\n')\n",
    "    elif line.startswith('[intro'):\n",
    "        lines.append('[intro] \\n')\n",
    "    elif line.startswith('[outro'):\n",
    "        lines.append('[outro] \\n')\n",
    "    elif line.startswith('[bridge'):\n",
    "        lines.append('[bridge] \\n')\n",
    "    elif line.startswith('[interlude'):\n",
    "        lines.append('[interlude] \\n')\n",
    "    elif line.startswith('lyrics for this'):\n",
    "        lines.append('\\n')\n",
    "    else:\n",
    "        lines.append(line)\n",
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_cleaned = open('all_lyrics_cleaned.txt', 'w')\n",
    "for line in lines:\n",
    "    all_lyrics_cleaned.write(line)\n",
    "all_lyrics_cleaned.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus is now  46686\n"
     ]
    }
   ],
   "source": [
    "# Read in the entire file.\n",
    "f = open('all_lyrics_cleaned.txt')\n",
    "corpus0 = f.read()\n",
    "f.close()\n",
    "\n",
    "# Separate the punctuation from the words, so that words with\n",
    "# punctuation do not get counted as distinct from words without\n",
    "# punctuation.  Same for new line characters.\n",
    "\n",
    "corpus0 = corpus0.replace(',', ' ,')\n",
    "corpus0 = corpus0.replace('(', ' ( ')\n",
    "corpus0 = corpus0.replace(')', ' ) ')\n",
    "corpus0 = corpus0.replace('[', ' [ ')\n",
    "corpus0 = corpus0.replace(']', ' ] ')\n",
    "corpus0 = corpus0.replace('.', ' . ')\n",
    "corpus0 = corpus0.replace(';', ' ; ')\n",
    "corpus0 = corpus0.replace(':', ' : ')\n",
    "corpus0 = corpus0.replace('!', ' ! ')\n",
    "corpus0 = corpus0.replace('?', ' ? ')\n",
    "corpus0 = corpus0.replace('*', ' * ')\n",
    "corpus0 = corpus0.replace(\"â€™\", '\\'')\n",
    "corpus0 = corpus0.replace(\"\\'\\'\", ' \" ')\n",
    "corpus0 = corpus0.replace('\"', ' \" ')\n",
    "corpus0 = corpus0.replace('\\r\\n', ' \\r\\n ')\n",
    "\n",
    "# Separate the dashes from any words they're attached to.\n",
    "corpus0 = corpus0.replace('-', ' - ')\n",
    "corpus0 = corpus0.replace('\\n', ' \\n ')\n",
    "\n",
    "# Convert the text to lower case.\n",
    "corpus0 = corpus0.lower()\n",
    "\n",
    "# Split the words by spaces; only take the first 500000 words.\n",
    "# This number was chosen based on memory limits and training-time\n",
    "# limitations.\n",
    "corpus1 = corpus0.split(' ')\n",
    "\n",
    "while (corpus1.count('') > 0): \n",
    "    corpus1.remove('')\n",
    "    \n",
    "print('Length of corpus is now ', len(corpus1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2476 different words.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing is done.  Now get the unique words, and encode them.\n",
    "words = sorted(list(set(corpus1)))\n",
    "num_words = len(words)\n",
    "encoding = {w: i for i, w in enumerate(words)}\n",
    "decoding = {i: w for i, w in enumerate(words)}\n",
    "\n",
    "print('We have', num_words, 'different words.')\n",
    "corpus = corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 46676 sentences.\n",
      "Encoding data.\n"
     ]
    }
   ],
   "source": [
    "# Chop up the data into x and y, slice into roughly num_chars\n",
    "# overlapping 'sentences' of length sentence_length.  Encode the\n",
    "# characters.\n",
    "sentence_length = 10\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(0, len(corpus) - sentence_length):\n",
    "    sentence = corpus[i: i + sentence_length]\n",
    "    next_word = corpus[i + sentence_length]\n",
    "    x_data.append([encoding[word] for word in sentence])\n",
    "    y_data.append(encoding[next_word])\n",
    "\n",
    "# good word: phronesis\n",
    "num_sentences = len(x_data)\n",
    "print('We have', len(x_data), 'sentences.')\n",
    "\n",
    "# Create the variables to hold the data as it will be used.\n",
    "x = np.zeros((num_sentences, sentence_length, num_words), dtype = np.bool)\n",
    "y = np.zeros((num_sentences, num_words), dtype = np.bool)\n",
    "\n",
    "# Populate the sentences.\n",
    "print('Encoding data.')\n",
    "for i, sentence in enumerate(x_data):\n",
    "    for t, encoded_word in enumerate(sentence):\n",
    "        x[i, t, encoded_word] = 1\n",
    "    y[i, y_data[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data.\n"
     ]
    }
   ],
   "source": [
    "# The processing of the data takes a fair amount of time.  Save\n",
    "# the data so we don't have to do this again.  We do this in a\n",
    "# numpy file since the data is large and the shelve can't handle\n",
    "# it.\n",
    "\n",
    "print('Saving processed data.')\n",
    "np.save('x.npy', x)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km\n",
    "import keras.layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network.\n"
     ]
    }
   ],
   "source": [
    "print('Building network.')\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(64, input_shape = (sentence_length, num_words)))\n",
    "model.add(kl.Dense(num_words, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fit.\n",
      "Epoch 1/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 7.7659 - acc: 0.1000\n",
      "Epoch 2/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 7.6643 - acc: 0.1016\n",
      "Epoch 3/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 7.5387 - acc: 0.1016\n",
      "Epoch 4/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 7.2959 - acc: 0.1016\n",
      "Epoch 5/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 6.6887 - acc: 0.1016\n",
      "Epoch 6/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 6.2307 - acc: 0.1016\n",
      "Epoch 7/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.9877 - acc: 0.1016\n",
      "Epoch 8/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.8042 - acc: 0.1016\n",
      "Epoch 9/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.6766 - acc: 0.1016\n",
      "Epoch 10/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.5910 - acc: 0.1016\n",
      "Epoch 11/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.5309 - acc: 0.1016\n",
      "Epoch 12/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.4873 - acc: 0.1016\n",
      "Epoch 13/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.4548 - acc: 0.1016\n",
      "Epoch 14/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.4301 - acc: 0.1016\n",
      "Epoch 15/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.4106 - acc: 0.1016\n",
      "Epoch 16/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3946 - acc: 0.1016\n",
      "Epoch 17/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3811 - acc: 0.1016\n",
      "Epoch 18/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3695 - acc: 0.1016\n",
      "Epoch 19/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3601 - acc: 0.1016\n",
      "Epoch 20/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3518 - acc: 0.1016\n",
      "Epoch 21/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3447 - acc: 0.1016\n",
      "Epoch 22/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3387 - acc: 0.1016\n",
      "Epoch 23/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3332 - acc: 0.1015\n",
      "Epoch 24/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3286 - acc: 0.1016\n",
      "Epoch 25/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3242 - acc: 0.1017\n",
      "Epoch 26/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3206 - acc: 0.1016\n",
      "Epoch 27/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3172 - acc: 0.1016\n",
      "Epoch 28/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3142 - acc: 0.1016\n",
      "Epoch 29/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3114 - acc: 0.1015\n",
      "Epoch 30/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.3090 - acc: 0.1016\n",
      "Epoch 31/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3066 - acc: 0.1016\n",
      "Epoch 32/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.3046 - acc: 0.1016\n",
      "Epoch 33/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3026 - acc: 0.1016\n",
      "Epoch 34/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.3009 - acc: 0.1016\n",
      "Epoch 35/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2992 - acc: 0.1016\n",
      "Epoch 36/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2976 - acc: 0.1016\n",
      "Epoch 37/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2963 - acc: 0.1016\n",
      "Epoch 38/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2949 - acc: 0.1016\n",
      "Epoch 39/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2936 - acc: 0.1016\n",
      "Epoch 40/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2925 - acc: 0.1016\n",
      "Epoch 41/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2913 - acc: 0.1016\n",
      "Epoch 42/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2903 - acc: 0.1016\n",
      "Epoch 43/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2893 - acc: 0.1016\n",
      "Epoch 44/200\n",
      "46676/46676 [==============================] - 20s 425us/step - loss: 5.2881 - acc: 0.1016\n",
      "Epoch 45/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2872 - acc: 0.1016\n",
      "Epoch 46/200\n",
      "46676/46676 [==============================] - 20s 424us/step - loss: 5.2864 - acc: 0.1016\n",
      "Epoch 47/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2854 - acc: 0.1018\n",
      "Epoch 48/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2847 - acc: 0.1016\n",
      "Epoch 49/200\n",
      "46676/46676 [==============================] - 20s 435us/step - loss: 5.2839 - acc: 0.1016\n",
      "Epoch 50/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2830 - acc: 0.1017\n",
      "Epoch 51/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2822 - acc: 0.1017\n",
      "Epoch 52/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2815 - acc: 0.1016\n",
      "Epoch 53/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2808 - acc: 0.1016\n",
      "Epoch 54/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2800 - acc: 0.1016\n",
      "Epoch 55/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2793 - acc: 0.1016\n",
      "Epoch 56/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2784 - acc: 0.1016\n",
      "Epoch 57/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2777 - acc: 0.1016\n",
      "Epoch 58/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2771 - acc: 0.1016\n",
      "Epoch 59/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2764 - acc: 0.1016\n",
      "Epoch 60/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2755 - acc: 0.1016\n",
      "Epoch 61/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2748 - acc: 0.1016\n",
      "Epoch 62/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2740 - acc: 0.1016\n",
      "Epoch 63/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2733 - acc: 0.1016\n",
      "Epoch 64/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2725 - acc: 0.1016\n",
      "Epoch 65/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2718 - acc: 0.1016\n",
      "Epoch 66/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2708 - acc: 0.1016\n",
      "Epoch 67/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2701 - acc: 0.1016\n",
      "Epoch 68/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2692 - acc: 0.1017\n",
      "Epoch 69/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2684 - acc: 0.1016\n",
      "Epoch 70/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2673 - acc: 0.1016\n",
      "Epoch 71/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2665 - acc: 0.1016\n",
      "Epoch 72/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2654 - acc: 0.1016\n",
      "Epoch 73/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2644 - acc: 0.1015\n",
      "Epoch 74/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2634 - acc: 0.1016\n",
      "Epoch 75/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2623 - acc: 0.1016\n",
      "Epoch 76/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2612 - acc: 0.1014\n",
      "Epoch 77/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2602 - acc: 0.1016\n",
      "Epoch 78/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2589 - acc: 0.1016\n",
      "Epoch 79/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2576 - acc: 0.1013\n",
      "Epoch 80/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2564 - acc: 0.1015\n",
      "Epoch 81/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2552 - acc: 0.1021\n",
      "Epoch 82/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2537 - acc: 0.1014\n",
      "Epoch 83/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2520 - acc: 0.1014\n",
      "Epoch 84/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2508 - acc: 0.1016\n",
      "Epoch 85/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2492 - acc: 0.1016\n",
      "Epoch 86/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2477 - acc: 0.1012\n",
      "Epoch 87/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2458 - acc: 0.1012\n",
      "Epoch 88/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2443 - acc: 0.1015\n",
      "Epoch 89/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2425 - acc: 0.1013\n",
      "Epoch 90/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2405 - acc: 0.1001\n",
      "Epoch 91/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2387 - acc: 0.1007\n",
      "Epoch 92/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.2368 - acc: 0.1008\n",
      "Epoch 93/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2347 - acc: 0.1006\n",
      "Epoch 94/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2326 - acc: 0.1003\n",
      "Epoch 95/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2304 - acc: 0.0993\n",
      "Epoch 96/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2283 - acc: 0.0992\n",
      "Epoch 97/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2261 - acc: 0.0998\n",
      "Epoch 98/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2237 - acc: 0.0997\n",
      "Epoch 99/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.2216 - acc: 0.0981\n",
      "Epoch 100/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2191 - acc: 0.0978\n",
      "Epoch 101/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2167 - acc: 0.0975\n",
      "Epoch 102/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2141 - acc: 0.0976\n",
      "Epoch 103/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2043 - acc: 0.0956\n",
      "Epoch 107/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.2017 - acc: 0.0949\n",
      "Epoch 108/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1992 - acc: 0.0964\n",
      "Epoch 109/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1966 - acc: 0.0957\n",
      "Epoch 110/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1942 - acc: 0.0967\n",
      "Epoch 111/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1916 - acc: 0.0973\n",
      "Epoch 112/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1893 - acc: 0.0973\n",
      "Epoch 113/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1868 - acc: 0.0985\n",
      "Epoch 114/200\n",
      "28288/46676 [=================>............] - ETA: 7s - loss: 5.1864 - acc: 0.0992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1479 - acc: 0.1251\n",
      "Epoch 134/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1463 - acc: 0.1262\n",
      "Epoch 135/200\n",
      "46676/46676 [==============================] - 20s 435us/step - loss: 5.1447 - acc: 0.1279\n",
      "Epoch 136/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1430 - acc: 0.1261\n",
      "Epoch 137/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1416 - acc: 0.1277\n",
      "Epoch 138/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1401 - acc: 0.1289\n",
      "Epoch 139/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1386 - acc: 0.1296\n",
      "Epoch 140/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1371 - acc: 0.1291\n",
      "Epoch 141/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1354 - acc: 0.1293\n",
      "Epoch 142/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1341 - acc: 0.1303\n",
      "Epoch 143/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1324 - acc: 0.1296\n",
      "Epoch 144/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1310 - acc: 0.1286\n",
      "Epoch 145/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1296 - acc: 0.1306\n",
      "Epoch 146/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1281 - acc: 0.1303\n",
      "Epoch 147/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1266 - acc: 0.1313\n",
      "Epoch 148/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1250 - acc: 0.1308\n",
      "Epoch 149/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1235 - acc: 0.1311\n",
      "Epoch 150/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1221 - acc: 0.1301\n",
      "Epoch 151/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1206 - acc: 0.1313\n",
      "Epoch 152/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.1190 - acc: 0.1317\n",
      "Epoch 153/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1175 - acc: 0.1325\n",
      "Epoch 154/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1161 - acc: 0.1325\n",
      "Epoch 155/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1146 - acc: 0.1325\n",
      "Epoch 156/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1129 - acc: 0.1324\n",
      "Epoch 157/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1114 - acc: 0.1323\n",
      "Epoch 158/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1098 - acc: 0.1329\n",
      "Epoch 159/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1082 - acc: 0.1325\n",
      "Epoch 160/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1066 - acc: 0.1337\n",
      "Epoch 161/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1049 - acc: 0.1333\n",
      "Epoch 162/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.1034 - acc: 0.1332\n",
      "Epoch 163/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1017 - acc: 0.1340\n",
      "Epoch 164/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.1000 - acc: 0.1358\n",
      "Epoch 165/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0985 - acc: 0.1364\n",
      "Epoch 166/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.0968 - acc: 0.1383\n",
      "Epoch 167/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 5.0951 - acc: 0.1383\n",
      "Epoch 168/200\n",
      "46676/46676 [==============================] - 20s 431us/step - loss: 5.0934 - acc: 0.1392\n",
      "Epoch 169/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0918 - acc: 0.1401\n",
      "Epoch 170/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0899 - acc: 0.1405\n",
      "Epoch 171/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0883 - acc: 0.1410\n",
      "Epoch 172/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0865 - acc: 0.1430\n",
      "Epoch 173/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0847 - acc: 0.1441\n",
      "Epoch 174/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0829 - acc: 0.1453\n",
      "Epoch 175/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0809 - acc: 0.1453\n",
      "Epoch 176/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0791 - acc: 0.1454\n",
      "Epoch 177/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0771 - acc: 0.1453\n",
      "Epoch 178/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0750 - acc: 0.1462\n",
      "Epoch 179/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0730 - acc: 0.1453\n",
      "Epoch 180/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0708 - acc: 0.1466\n",
      "Epoch 181/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0683 - acc: 0.1469\n",
      "Epoch 182/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0657 - acc: 0.1469\n",
      "Epoch 183/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0628 - acc: 0.1471\n",
      "Epoch 184/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0594 - acc: 0.1474\n",
      "Epoch 185/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0553 - acc: 0.1479\n",
      "Epoch 186/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0507 - acc: 0.1480\n",
      "Epoch 187/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0460 - acc: 0.1482\n",
      "Epoch 188/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0412 - acc: 0.1481\n",
      "Epoch 189/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0358 - acc: 0.1485\n",
      "Epoch 190/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0312 - acc: 0.1492\n",
      "Epoch 191/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0251 - acc: 0.1491\n",
      "Epoch 192/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0197 - acc: 0.1494\n",
      "Epoch 193/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0143 - acc: 0.1493\n",
      "Epoch 194/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 5.0082 - acc: 0.1498\n",
      "Epoch 195/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 5.0018 - acc: 0.1515\n",
      "Epoch 196/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.9962 - acc: 0.1546\n",
      "Epoch 197/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.9898 - acc: 0.1605\n",
      "Epoch 198/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.9838 - acc: 0.1636\n",
      "Epoch 199/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9779 - acc: 0.1669\n",
      "Epoch 200/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9714 - acc: 0.1691\n"
     ]
    }
   ],
   "source": [
    "# Fit!  Begin elevator music...\n",
    "print('Beginning fit.')\n",
    "fit = model.fit(x, y, epochs = 200, batch_size = 128)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9661 - acc: 0.1712\n",
      "Epoch 2/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9606 - acc: 0.1737\n",
      "Epoch 3/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9556 - acc: 0.1740\n",
      "Epoch 4/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9492 - acc: 0.1766\n",
      "Epoch 5/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.9438 - acc: 0.1781\n",
      "Epoch 6/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.9389 - acc: 0.1803\n",
      "Epoch 7/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.9346 - acc: 0.1809\n",
      "Epoch 8/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.9291 - acc: 0.1836\n",
      "Epoch 9/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9248 - acc: 0.1844\n",
      "Epoch 10/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9201 - acc: 0.1860\n",
      "Epoch 11/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9150 - acc: 0.1872\n",
      "Epoch 12/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9113 - acc: 0.1876\n",
      "Epoch 13/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9066 - acc: 0.1880\n",
      "Epoch 14/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.9028 - acc: 0.1884\n",
      "Epoch 15/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8996 - acc: 0.1884\n",
      "Epoch 16/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8962 - acc: 0.1899\n",
      "Epoch 17/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8930 - acc: 0.1890\n",
      "Epoch 18/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8897 - acc: 0.1895\n",
      "Epoch 19/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.8865 - acc: 0.1898\n",
      "Epoch 20/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.8834 - acc: 0.1901\n",
      "Epoch 21/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.8801 - acc: 0.1902\n",
      "Epoch 22/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8775 - acc: 0.1904\n",
      "Epoch 23/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8742 - acc: 0.1908\n",
      "Epoch 24/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8713 - acc: 0.1906\n",
      "Epoch 25/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8687 - acc: 0.1908\n",
      "Epoch 26/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8661 - acc: 0.1913\n",
      "Epoch 27/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8638 - acc: 0.1914\n",
      "Epoch 28/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8611 - acc: 0.1916\n",
      "Epoch 29/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8585 - acc: 0.1915\n",
      "Epoch 30/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.8564 - acc: 0.1917\n",
      "Epoch 31/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8537 - acc: 0.1916\n",
      "Epoch 32/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8511 - acc: 0.1920\n",
      "Epoch 33/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8487 - acc: 0.1920\n",
      "Epoch 34/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8466 - acc: 0.1917\n",
      "Epoch 35/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8439 - acc: 0.1924\n",
      "Epoch 36/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8419 - acc: 0.1917\n",
      "Epoch 37/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8399 - acc: 0.1916\n",
      "Epoch 38/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8374 - acc: 0.1915\n",
      "Epoch 39/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8354 - acc: 0.1920\n",
      "Epoch 40/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8329 - acc: 0.1915\n",
      "Epoch 41/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8312 - acc: 0.1916\n",
      "Epoch 42/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8284 - acc: 0.1921\n",
      "Epoch 43/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8267 - acc: 0.1913\n",
      "Epoch 44/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8246 - acc: 0.1918\n",
      "Epoch 45/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8221 - acc: 0.1913\n",
      "Epoch 46/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8203 - acc: 0.1911\n",
      "Epoch 47/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8184 - acc: 0.1913\n",
      "Epoch 48/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8162 - acc: 0.1911\n",
      "Epoch 49/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8147 - acc: 0.1910\n",
      "Epoch 50/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8123 - acc: 0.1908\n",
      "Epoch 51/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8107 - acc: 0.1910\n",
      "Epoch 52/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8083 - acc: 0.1908\n",
      "Epoch 53/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8063 - acc: 0.1908\n",
      "Epoch 54/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.8045 - acc: 0.1905\n",
      "Epoch 55/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8022 - acc: 0.1912\n",
      "Epoch 56/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.8005 - acc: 0.1905\n",
      "Epoch 57/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7986 - acc: 0.1911\n",
      "Epoch 58/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7967 - acc: 0.1918\n",
      "Epoch 59/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7950 - acc: 0.1910\n",
      "Epoch 60/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7930 - acc: 0.1918\n",
      "Epoch 61/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7915 - acc: 0.1921\n",
      "Epoch 62/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7894 - acc: 0.1929\n",
      "Epoch 63/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7877 - acc: 0.1925\n",
      "Epoch 64/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7857 - acc: 0.1925\n",
      "Epoch 65/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7841 - acc: 0.1928\n",
      "Epoch 66/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7811 - acc: 0.1937\n",
      "Epoch 67/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7803 - acc: 0.1939\n",
      "Epoch 68/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.7778 - acc: 0.1944\n",
      "Epoch 69/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7752 - acc: 0.1957\n",
      "Epoch 70/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7727 - acc: 0.1953\n",
      "Epoch 71/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7711 - acc: 0.1971\n",
      "Epoch 72/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7670 - acc: 0.1973\n",
      "Epoch 73/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7649 - acc: 0.1972\n",
      "Epoch 74/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7611 - acc: 0.1991\n",
      "Epoch 75/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7578 - acc: 0.2008\n",
      "Epoch 76/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7549 - acc: 0.2009\n",
      "Epoch 77/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7516 - acc: 0.2019\n",
      "Epoch 78/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7472 - acc: 0.2046\n",
      "Epoch 79/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.7437 - acc: 0.2046\n",
      "Epoch 80/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.7394 - acc: 0.2060\n",
      "Epoch 81/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7375 - acc: 0.2047\n",
      "Epoch 82/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7330 - acc: 0.2070\n",
      "Epoch 83/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7284 - acc: 0.2074\n",
      "Epoch 84/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7247 - acc: 0.2091\n",
      "Epoch 85/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7213 - acc: 0.2094\n",
      "Epoch 86/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7154 - acc: 0.2140\n",
      "Epoch 87/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7129 - acc: 0.2159\n",
      "Epoch 88/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7083 - acc: 0.2170\n",
      "Epoch 89/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.7045 - acc: 0.2168\n",
      "Epoch 90/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.7002 - acc: 0.2193\n",
      "Epoch 91/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6958 - acc: 0.2198\n",
      "Epoch 92/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6912 - acc: 0.2213\n",
      "Epoch 93/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6874 - acc: 0.2216\n",
      "Epoch 94/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6842 - acc: 0.2213\n",
      "Epoch 95/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6795 - acc: 0.2216\n",
      "Epoch 96/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6747 - acc: 0.2225\n",
      "Epoch 97/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6707 - acc: 0.2234\n",
      "Epoch 98/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6671 - acc: 0.2232\n",
      "Epoch 99/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6622 - acc: 0.2230\n",
      "Epoch 100/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6592 - acc: 0.2248\n",
      "Epoch 101/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6550 - acc: 0.2253\n",
      "Epoch 102/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6519 - acc: 0.2258\n",
      "Epoch 103/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6471 - acc: 0.2257\n",
      "Epoch 104/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6439 - acc: 0.2260\n",
      "Epoch 105/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6407 - acc: 0.2274\n",
      "Epoch 106/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6371 - acc: 0.2278\n",
      "Epoch 107/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6335 - acc: 0.2282\n",
      "Epoch 108/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6295 - acc: 0.2292\n",
      "Epoch 109/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6270 - acc: 0.2289\n",
      "Epoch 110/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6230 - acc: 0.2292\n",
      "Epoch 111/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6208 - acc: 0.2299\n",
      "Epoch 112/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6163 - acc: 0.2309\n",
      "Epoch 113/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6147 - acc: 0.2301\n",
      "Epoch 114/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6094 - acc: 0.2317\n",
      "Epoch 115/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.6076 - acc: 0.2320\n",
      "Epoch 116/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6046 - acc: 0.2323\n",
      "Epoch 117/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.6010 - acc: 0.2337\n",
      "Epoch 118/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5984 - acc: 0.2342\n",
      "Epoch 119/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5950 - acc: 0.2347\n",
      "Epoch 120/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5913 - acc: 0.2354\n",
      "Epoch 121/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5896 - acc: 0.2350\n",
      "Epoch 122/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5852 - acc: 0.2356\n",
      "Epoch 123/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5815 - acc: 0.2382\n",
      "Epoch 124/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5791 - acc: 0.2371\n",
      "Epoch 125/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5759 - acc: 0.2385\n",
      "Epoch 126/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5729 - acc: 0.2385\n",
      "Epoch 127/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5702 - acc: 0.2389\n",
      "Epoch 128/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5673 - acc: 0.2390\n",
      "Epoch 129/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5643 - acc: 0.2392\n",
      "Epoch 130/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5621 - acc: 0.2395\n",
      "Epoch 131/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5577 - acc: 0.2411\n",
      "Epoch 132/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5551 - acc: 0.2425\n",
      "Epoch 133/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5520 - acc: 0.2418\n",
      "Epoch 134/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5490 - acc: 0.2424\n",
      "Epoch 135/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5464 - acc: 0.2427\n",
      "Epoch 136/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5421 - acc: 0.2436\n",
      "Epoch 137/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5395 - acc: 0.2439\n",
      "Epoch 138/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5373 - acc: 0.2440\n",
      "Epoch 139/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.5340 - acc: 0.2452\n",
      "Epoch 140/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5297 - acc: 0.2452\n",
      "Epoch 141/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5275 - acc: 0.2459\n",
      "Epoch 142/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5244 - acc: 0.2475\n",
      "Epoch 143/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5215 - acc: 0.2481\n",
      "Epoch 144/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5185 - acc: 0.2477\n",
      "Epoch 145/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5159 - acc: 0.2482\n",
      "Epoch 146/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5110 - acc: 0.2495\n",
      "Epoch 147/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5089 - acc: 0.2489\n",
      "Epoch 148/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.5059 - acc: 0.2501\n",
      "Epoch 149/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.5014 - acc: 0.2503\n",
      "Epoch 150/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4990 - acc: 0.2515\n",
      "Epoch 151/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4962 - acc: 0.2528\n",
      "Epoch 152/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4947 - acc: 0.2526\n",
      "Epoch 153/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4896 - acc: 0.2562\n",
      "Epoch 154/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4865 - acc: 0.2563\n",
      "Epoch 155/200\n",
      "46676/46676 [==============================] - 20s 426us/step - loss: 4.4837 - acc: 0.2586\n",
      "Epoch 156/200\n",
      "46676/46676 [==============================] - 21s 440us/step - loss: 4.4789 - acc: 0.2594\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.4771 - acc: 0.2600\n",
      "Epoch 158/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4742 - acc: 0.2606\n",
      "Epoch 159/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4704 - acc: 0.2616\n",
      "Epoch 160/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4674 - acc: 0.2633\n",
      "Epoch 161/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4637 - acc: 0.2628\n",
      "Epoch 162/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4605 - acc: 0.2628\n",
      "Epoch 163/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4570 - acc: 0.2649\n",
      "Epoch 164/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4553 - acc: 0.2640\n",
      "Epoch 165/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4511 - acc: 0.2645\n",
      "Epoch 166/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4490 - acc: 0.2648\n",
      "Epoch 167/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4450 - acc: 0.2657\n",
      "Epoch 168/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4408 - acc: 0.2661\n",
      "Epoch 169/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.4393 - acc: 0.2662\n",
      "Epoch 170/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.4357 - acc: 0.2663\n",
      "Epoch 171/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4315 - acc: 0.2668\n",
      "Epoch 172/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4299 - acc: 0.2678\n",
      "Epoch 173/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.4249 - acc: 0.2689\n",
      "Epoch 174/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4226 - acc: 0.2680\n",
      "Epoch 175/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4184 - acc: 0.2693\n",
      "Epoch 176/200\n",
      "46676/46676 [==============================] - 20s 429us/step - loss: 4.4165 - acc: 0.2686\n",
      "Epoch 177/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.4129 - acc: 0.2694\n",
      "Epoch 178/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4089 - acc: 0.2705\n",
      "Epoch 179/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4064 - acc: 0.2699\n",
      "Epoch 180/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4026 - acc: 0.2702\n",
      "Epoch 181/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.4002 - acc: 0.2722\n",
      "Epoch 182/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.3968 - acc: 0.2714\n",
      "Epoch 183/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3938 - acc: 0.2720\n",
      "Epoch 184/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3898 - acc: 0.2726\n",
      "Epoch 185/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3870 - acc: 0.2733\n",
      "Epoch 186/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3835 - acc: 0.2735\n",
      "Epoch 187/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3802 - acc: 0.2742\n",
      "Epoch 188/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3768 - acc: 0.2740\n",
      "Epoch 189/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3748 - acc: 0.2732\n",
      "Epoch 190/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3703 - acc: 0.2760\n",
      "Epoch 191/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3667 - acc: 0.2750\n",
      "Epoch 192/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.3641 - acc: 0.2750\n",
      "Epoch 193/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3600 - acc: 0.2765\n",
      "Epoch 194/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3567 - acc: 0.2758\n",
      "Epoch 195/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3538 - acc: 0.2770\n",
      "Epoch 196/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3513 - acc: 0.2765\n",
      "Epoch 197/200\n",
      "46676/46676 [==============================] - 20s 428us/step - loss: 4.3468 - acc: 0.2778\n",
      "Epoch 198/200\n",
      "46676/46676 [==============================] - 20s 427us/step - loss: 4.3447 - acc: 0.2768\n",
      "Epoch 199/200\n",
      "46676/46676 [==============================] - 20s 430us/step - loss: 4.3400 - acc: 0.2780\n",
      "Epoch 200/200\n",
      "46676/46676 [==============================] - 20s 432us/step - loss: 4.3389 - acc: 0.2778\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(x, y, epochs = 200, batch_size = 128)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "46676/46676 [==============================] - 22s 463us/step - loss: 0.9019 - acc: 0.8333\n",
      "Epoch 2/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.9049 - acc: 0.8324\n",
      "Epoch 3/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.8999 - acc: 0.8323\n",
      "Epoch 4/200\n",
      "46676/46676 [==============================] - 21s 447us/step - loss: 0.9229 - acc: 0.8274\n",
      "Epoch 5/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9222 - acc: 0.8273\n",
      "Epoch 6/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9278 - acc: 0.8261\n",
      "Epoch 7/200\n",
      "46676/46676 [==============================] - 21s 448us/step - loss: 0.9044 - acc: 0.8319\n",
      "Epoch 8/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9163 - acc: 0.8288\n",
      "Epoch 9/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9115 - acc: 0.8300\n",
      "Epoch 10/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9040 - acc: 0.8319\n",
      "Epoch 11/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9147 - acc: 0.8287\n",
      "Epoch 12/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9168 - acc: 0.8293\n",
      "Epoch 13/200\n",
      "46676/46676 [==============================] - 21s 444us/step - loss: 0.9182 - acc: 0.8279\n",
      "Epoch 14/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9114 - acc: 0.8305\n",
      "Epoch 15/200\n",
      "46676/46676 [==============================] - 21s 444us/step - loss: 0.9242 - acc: 0.8271\n",
      "Epoch 16/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.9097 - acc: 0.8291\n",
      "Epoch 17/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9166 - acc: 0.8289\n",
      "Epoch 18/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8957 - acc: 0.8343\n",
      "Epoch 19/200\n",
      "46676/46676 [==============================] - 21s 449us/step - loss: 0.9267 - acc: 0.8253\n",
      "Epoch 20/200\n",
      "46676/46676 [==============================] - 21s 448us/step - loss: 0.9110 - acc: 0.8280\n",
      "Epoch 21/200\n",
      "46676/46676 [==============================] - 21s 451us/step - loss: 0.9001 - acc: 0.8332\n",
      "Epoch 22/200\n",
      "46676/46676 [==============================] - 21s 450us/step - loss: 0.8983 - acc: 0.8336\n",
      "Epoch 23/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9086 - acc: 0.8298\n",
      "Epoch 24/200\n",
      "46676/46676 [==============================] - 21s 444us/step - loss: 0.9164 - acc: 0.8283\n",
      "Epoch 25/200\n",
      "46676/46676 [==============================] - 21s 447us/step - loss: 0.9096 - acc: 0.8296\n",
      "Epoch 26/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9109 - acc: 0.8288\n",
      "Epoch 27/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8902 - acc: 0.8348\n",
      "Epoch 28/200\n",
      "46676/46676 [==============================] - 22s 463us/step - loss: 0.9271 - acc: 0.8247\n",
      "Epoch 29/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9299 - acc: 0.8252\n",
      "Epoch 30/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9102 - acc: 0.8305\n",
      "Epoch 31/200\n",
      "46676/46676 [==============================] - 21s 454us/step - loss: 0.9105 - acc: 0.8302\n",
      "Epoch 32/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9119 - acc: 0.8288\n",
      "Epoch 33/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.9071 - acc: 0.8316\n",
      "Epoch 34/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.8946 - acc: 0.8329\n",
      "Epoch 35/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.8990 - acc: 0.8313\n",
      "Epoch 36/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.9181 - acc: 0.8262\n",
      "Epoch 37/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.9171 - acc: 0.8269\n",
      "Epoch 38/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.8853 - acc: 0.8352\n",
      "Epoch 39/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9113 - acc: 0.8291\n",
      "Epoch 40/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9154 - acc: 0.8277\n",
      "Epoch 41/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9032 - acc: 0.8313\n",
      "Epoch 42/200\n",
      "46676/46676 [==============================] - 21s 447us/step - loss: 0.8836 - acc: 0.8363\n",
      "Epoch 43/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9099 - acc: 0.8299\n",
      "Epoch 44/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8923 - acc: 0.8337\n",
      "Epoch 45/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9041 - acc: 0.8298\n",
      "Epoch 46/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8852 - acc: 0.8362\n",
      "Epoch 47/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9094 - acc: 0.8285\n",
      "Epoch 48/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8992 - acc: 0.8314\n",
      "Epoch 49/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.9285 - acc: 0.8235\n",
      "Epoch 50/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8914 - acc: 0.8333\n",
      "Epoch 51/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8814 - acc: 0.8357\n",
      "Epoch 52/200\n",
      "46676/46676 [==============================] - 21s 446us/step - loss: 0.8815 - acc: 0.8357\n",
      "Epoch 53/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9078 - acc: 0.8289\n",
      "Epoch 54/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.8961 - acc: 0.8330\n",
      "Epoch 55/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8899 - acc: 0.8341\n",
      "Epoch 56/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.8779 - acc: 0.8370\n",
      "Epoch 57/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8942 - acc: 0.8315\n",
      "Epoch 58/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8946 - acc: 0.8325\n",
      "Epoch 59/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8863 - acc: 0.8342\n",
      "Epoch 60/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.9215 - acc: 0.8255\n",
      "Epoch 61/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.9075 - acc: 0.8288\n",
      "Epoch 62/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8782 - acc: 0.8360\n",
      "Epoch 63/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.8833 - acc: 0.8351\n",
      "Epoch 64/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.8838 - acc: 0.8358\n",
      "Epoch 65/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8909 - acc: 0.8325\n",
      "Epoch 66/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8740 - acc: 0.8379\n",
      "Epoch 67/200\n",
      "46676/46676 [==============================] - 21s 442us/step - loss: 0.8806 - acc: 0.8351\n",
      "Epoch 68/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8715 - acc: 0.8386\n",
      "Epoch 69/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8955 - acc: 0.8316\n",
      "Epoch 70/200\n",
      "46676/46676 [==============================] - 21s 443us/step - loss: 0.8921 - acc: 0.8325\n",
      "Epoch 71/200\n",
      "46676/46676 [==============================] - 21s 444us/step - loss: 0.8920 - acc: 0.8336\n",
      "Epoch 72/200\n",
      "46676/46676 [==============================] - 21s 448us/step - loss: 0.8845 - acc: 0.8352\n",
      "Epoch 73/200\n",
      "46676/46676 [==============================] - 21s 444us/step - loss: 0.8831 - acc: 0.8351\n",
      "Epoch 74/200\n",
      "46676/46676 [==============================] - 21s 447us/step - loss: 0.8753 - acc: 0.8371\n",
      "Epoch 75/200\n",
      "46676/46676 [==============================] - 21s 445us/step - loss: 0.8806 - acc: 0.8347\n",
      "Epoch 76/200\n",
      "44288/46676 [===========================>..] - ETA: 1s - loss: 0.9012 - acc: 0.8298"
     ]
    }
   ],
   "source": [
    "fit = model.fit(x, y, epochs = 200, batch_size = 128)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model file.\n",
      "Generated lyrics: \n",
      "\n",
      "( skrr ) \n",
      " yeah ) , my lean , i don't broke the ( okay ) \n",
      " i pump the school , do you a couple ) \n",
      " all you you do it just me me like me . yeah \n",
      " yeah [ chorus : : : ] \n",
      " lil pump \n",
      " [ chorus ] \n",
      " ouu , yuh \n",
      " yuh , yuh , yeah \n",
      " boppin' [ chorus ] \n",
      " ayy , no bitch , no know go flex ? ) \n",
      " bitch i think go cars , pack \n",
      " louis and lil pump , no all , i got my wrist ( ooh ) for that four on the wrist \n",
      " and ride designer pack like the damn \n",
      " \n",
      " [ chorus ] \n",
      " fuck so bitches in the trap \n",
      " \n",
      " [ verse ] \n",
      " lil pump told that lil' pump , i got up in \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras.models as km\n",
    "import shelve\n",
    "import random\n",
    "\n",
    "modelfile = 'model.h5'\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "# Get the model.\n",
    "print('Reading model file.')\n",
    "model = km.load_model(modelfile)\n",
    "\n",
    "# Get the meta-data.\n",
    "\n",
    "sentence_length = 10\n",
    "num_words = 2476\n",
    "\n",
    "\n",
    "# Randomly choose 50 words from the dictionary of words as our\n",
    "# starting sentence.\n",
    "seed = []\n",
    "for i in range(sentence_length):\n",
    "    seed.append(decoding[random.randint(0, num_words - 1)])\n",
    "\n",
    "\n",
    "# Encode the seed sentence.\n",
    "x = np.zeros((1, sentence_length, num_words), dtype = np.bool)\n",
    "for i, w in enumerate(seed):\n",
    "    x[0, i, encoding[w]] = 1\n",
    "\n",
    "text = ''\n",
    "\n",
    "# Run the seed sentence through the model.  Add the output to the\n",
    "# generated text.  Take the output and append it to the seed sentence\n",
    "# and remove the first word from the seed sentence.  Then repeat until\n",
    "# you've generated as many words as you like.\n",
    "for i in range(150):\n",
    "\n",
    "    # Get the most-probably next word.\n",
    "    pred = np.argmax(model.predict(x, verbose = 0))\n",
    "\n",
    "    # Add it to the generated text.\n",
    "    text += decoding[pred] + ' '\n",
    "\n",
    "    # Encode the next word.\n",
    "    next_word = np.zeros((1, 1, num_words), dtype = np.bool)\n",
    "    next_word[0, 0, pred] = 1\n",
    "\n",
    "    # Concatenate the next word to the seed sentence, but leave off\n",
    "    # the first element so that the length stays the same.\n",
    "    x = np.concatenate((x[:, 1:, :], next_word), axis = 1)\n",
    "\n",
    "    \n",
    "# Print out the generated text.\n",
    "print(\"Generated lyrics: \\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
