{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lyrics_titles_AutoPump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 Choppa 2 Choppa*</td>\n",
       "      <td>[Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30's</td>\n",
       "      <td>[Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70 Nigga</td>\n",
       "      <td>\\r\\n            Lyrics for this song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Aight</td>\n",
       "      <td>[Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>At the Door</td>\n",
       "      <td>[Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               title  \\\n",
       "0           0  1 Choppa 2 Choppa*   \n",
       "1           0                30's   \n",
       "2           0            70 Nigga   \n",
       "3           0               Aight   \n",
       "4           0         At the Door   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...  \n",
       "1  [Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...  \n",
       "2            \\r\\n            Lyrics for this song...  \n",
       "3  [Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...  \n",
       "4  [Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = open('all_lyrics.txt', 'w')\n",
    "for row in data.itertuples():\n",
    "    text = row.lyrics\n",
    "    title = row.title\n",
    "    if text.startswith('     '):\n",
    "        continue\n",
    "    all_lyrics.write(title + '\\n')\n",
    "    all_lyrics.write('********************\\n')\n",
    "    all_lyrics.write(text + '\\n')\n",
    "    all_lyrics.write('********************\\n\\n\\n')\n",
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "all_lyrics = open('all_lyrics.txt', 'r')\n",
    "for line in all_lyrics:\n",
    "    if line.startswith(' '):\n",
    "        line = line.lstrip()\n",
    "    line = line.lower()\n",
    "    if line.startswith('[chorus'):\n",
    "        lines.append('[chorus] \\n')\n",
    "    elif line.startswith('[verse'):\n",
    "        lines.append('[verse] \\n')\n",
    "    elif line.startswith('[hook'):\n",
    "        lines.append('[hook] \\n')\n",
    "    elif line.startswith('[intro'):\n",
    "        lines.append('[intro] \\n')\n",
    "    elif line.startswith('[outro'):\n",
    "        lines.append('[outro] \\n')\n",
    "    elif line.startswith('[bridge'):\n",
    "        lines.append('[bridge] \\n')\n",
    "    elif line.startswith('[interlude'):\n",
    "        lines.append('[interlude] \\n')\n",
    "    elif line.startswith('lyrics for this'):\n",
    "        lines.append('\\n')\n",
    "    else:\n",
    "        lines.append(line)\n",
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_cleaned = open('all_lyrics_cleaned.txt', 'w')\n",
    "for line in lines:\n",
    "    all_lyrics_cleaned.write(line)\n",
    "all_lyrics_cleaned.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus is now  46584\n"
     ]
    }
   ],
   "source": [
    "# Read in the entire file.\n",
    "f = open('all_lyrics_cleaned.txt')\n",
    "corpus0 = f.read()\n",
    "f.close()\n",
    "\n",
    "# Separate the punctuation from the words, so that words with\n",
    "# punctuation do not get counted as distinct from words without\n",
    "# punctuation.  Same for new line characters.\n",
    "\n",
    "corpus0 = corpus0.replace(',', ' ,')\n",
    "corpus0 = corpus0.replace('(', ' ( ')\n",
    "corpus0 = corpus0.replace(')', ' ) ')\n",
    "#corpus0 = corpus0.replace('[', ' [ ')\n",
    "#corpus0 = corpus0.replace(']', ' ] ')\n",
    "corpus0 = corpus0.replace('.', ' . ')\n",
    "corpus0 = corpus0.replace(';', ' ; ')\n",
    "corpus0 = corpus0.replace(':', ' : ')\n",
    "corpus0 = corpus0.replace('!', ' ! ')\n",
    "corpus0 = corpus0.replace('?', ' ? ')\n",
    "corpus0 = corpus0.replace('********************', ' ******************** ')\n",
    "#corpus0 = corpus0.replace('*', ' * ')\n",
    "corpus0 = corpus0.replace(\"â€™\", '\\'')\n",
    "corpus0 = corpus0.replace(\"\\'\\'\", ' \" ')\n",
    "corpus0 = corpus0.replace('\"', ' \" ')\n",
    "corpus0 = corpus0.replace('\\r\\n', ' \\r\\n ')\n",
    "\n",
    "# Separate the dashes from any words they're attached to.\n",
    "corpus0 = corpus0.replace('-', ' - ')\n",
    "corpus0 = corpus0.replace('\\n', ' \\n ')\n",
    "\n",
    "# Convert the text to lower case.\n",
    "corpus0 = corpus0.lower()\n",
    "\n",
    "# Split the words by spaces; only take the first 500000 words.\n",
    "# This number was chosen based on memory limits and training-time\n",
    "# limitations.\n",
    "corpus1 = corpus0.split(' ')\n",
    "\n",
    "while (corpus1.count('') > 0): \n",
    "    corpus1.remove('')\n",
    "    \n",
    "print('Length of corpus is now ', len(corpus1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2500 different words.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing is done.  Now get the unique words, and encode them.\n",
    "words = sorted(list(set(corpus1)))\n",
    "num_words = len(words)\n",
    "encoding = {w: i for i, w in enumerate(words)}\n",
    "decoding = {i: w for i, w in enumerate(words)}\n",
    "\n",
    "print('We have', num_words, 'different words.')\n",
    "corpus = corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 46534 sentences.\n",
      "Encoding data.\n"
     ]
    }
   ],
   "source": [
    "# Chop up the data into x and y, slice into roughly num_chars\n",
    "# overlapping 'sentences' of length sentence_length.  Encode the\n",
    "# characters.\n",
    "sentence_length = 50\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(0, len(corpus) - sentence_length):\n",
    "    sentence = corpus[i: i + sentence_length]\n",
    "    next_word = corpus[i + sentence_length]\n",
    "    x_data.append([encoding[word] for word in sentence])\n",
    "    y_data.append(encoding[next_word])\n",
    "\n",
    "# good word: phronesis\n",
    "num_sentences = len(x_data)\n",
    "print('We have', len(x_data), 'sentences.')\n",
    "\n",
    "# Create the variables to hold the data as it will be used.\n",
    "x = np.zeros((num_sentences, sentence_length, num_words), dtype = np.bool)\n",
    "y = np.zeros((num_sentences, num_words), dtype = np.bool)\n",
    "\n",
    "# Populate the sentences.\n",
    "print('Encoding data.')\n",
    "for i, sentence in enumerate(x_data):\n",
    "    for t, encoded_word in enumerate(sentence):\n",
    "        x[i, t, encoded_word] = 1\n",
    "    y[i, y_data[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data.\n"
     ]
    }
   ],
   "source": [
    "# The processing of the data takes a fair amount of time.  Save\n",
    "# the data so we don't have to do this again.  We do this in a\n",
    "# numpy file since the data is large and the shelve can't handle\n",
    "# it.\n",
    "\n",
    "print('Saving processed data.')\n",
    "np.save('x.npy', x)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km\n",
    "import keras.layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network.\n"
     ]
    }
   ],
   "source": [
    "print('Building network.')\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(128, input_shape = (sentence_length, num_words)))\n",
    "model.add(kl.Dense(num_words, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fit.\n",
      "Epoch 1/200\n",
      "46534/46534 [==============================] - 104s 2ms/step - loss: 5.5129 - acc: 0.1120\n",
      "Epoch 2/200\n",
      "46534/46534 [==============================] - 104s 2ms/step - loss: 5.4754 - acc: 0.1120\n",
      "Epoch 3/200\n",
      "46534/46534 [==============================] - 104s 2ms/step - loss: 5.4460 - acc: 0.1120\n",
      "Epoch 4/200\n",
      "46534/46534 [==============================] - 104s 2ms/step - loss: 5.4223 - acc: 0.1120\n",
      "Epoch 5/200\n",
      "46534/46534 [==============================] - 105s 2ms/step - loss: 5.4028 - acc: 0.1120\n",
      "Epoch 6/200\n",
      "46534/46534 [==============================] - 105s 2ms/step - loss: 5.3865 - acc: 0.1120\n",
      "Epoch 7/200\n",
      "14848/46534 [========>.....................] - ETA: 1:11 - loss: 5.3930 - acc: 0.1136"
     ]
    }
   ],
   "source": [
    "# Fit!  Begin elevator music...\n",
    "print('Beginning fit.')\n",
    "fit = model.fit(x, y, epochs = 200, batch_size = 256)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model_50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This piece of code will load the saved model from the file and generate a song from the initial seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model file.\n",
      "Generated lyrics: \n",
      "\n",
      "on \n",
      " came the , wok your whitney , cry , ooh , i do it \n",
      " yeah , bitch , i ain't , these shit , ooh your stop ) \n",
      " yeah , niggas in you we from like a coupe ( damn ) \n",
      " she around this dick on make her is i i'm ) \n",
      " i sell at the money , boy got a new and yeah \n",
      " dropped bitch i got i new shit \n",
      " jump i fuckin' in your bitch , go go jump \n",
      " \n",
      " [ intro ] \n",
      " lil pump lil pump , lil pump , lil pump , i don't up a bitch ( esskeetit ) \n",
      " rather up go lean ) \n",
      " i i just left 'em ( don't ) \n",
      " to to xan at go , and i think off \n",
      " \n",
      " [ intro ] \n",
      " yeah pump , yeah \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras.models as km\n",
    "import shelve\n",
    "import random\n",
    "\n",
    "modelfile = 'model_50.h5'\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "# Get the model.\n",
    "print('Reading model file.')\n",
    "model = km.load_model(modelfile)\n",
    "\n",
    "# Get the meta-data.\n",
    "\n",
    "sentence_length = 50\n",
    "num_words = 2500\n",
    "\n",
    "\n",
    "# Randomly choose 50 words from the dictionary of words as our\n",
    "# starting sentence.\n",
    "seed = []\n",
    "for i in range(sentence_length):\n",
    "    seed.append(decoding[random.randint(0, num_words - 1)])\n",
    "\n",
    "\n",
    "# Encode the seed sentence.\n",
    "x = np.zeros((1, sentence_length, num_words), dtype = np.bool)\n",
    "for i, w in enumerate(seed):\n",
    "    x[0, i, encoding[w]] = 1\n",
    "\n",
    "text = ''\n",
    "\n",
    "# Run the seed sentence through the model.  Add the output to the\n",
    "# generated text.  Take the output and append it to the seed sentence\n",
    "# and remove the first word from the seed sentence.  Then repeat until\n",
    "# you've generated as many words as you like.\n",
    "for i in range(150):\n",
    "\n",
    "    # Get the most-probably next word.\n",
    "    pred = np.argmax(model.predict(x, verbose = 0))\n",
    "\n",
    "    # Add it to the generated text.\n",
    "    text += decoding[pred] + ' '\n",
    "\n",
    "    # Encode the next word.\n",
    "    next_word = np.zeros((1, 1, num_words), dtype = np.bool)\n",
    "    next_word[0, 0, pred] = 1\n",
    "\n",
    "    # Concatenate the next word to the seed sentence, but leave off\n",
    "    # the first element so that the length stays the same.\n",
    "    x = np.concatenate((x[:, 1:, :], next_word), axis = 1)\n",
    "\n",
    "    \n",
    "# Print out the generated text.\n",
    "print(\"Generated lyrics: \\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
