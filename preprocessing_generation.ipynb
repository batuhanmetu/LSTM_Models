{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lyrics_titles_AutoPump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1 Choppa 2 Choppa*</td>\n",
       "      <td>[Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30's</td>\n",
       "      <td>[Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70 Nigga</td>\n",
       "      <td>\\r\\n            Lyrics for this song...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Aight</td>\n",
       "      <td>[Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>At the Door</td>\n",
       "      <td>[Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               title  \\\n",
       "0           0  1 Choppa 2 Choppa*   \n",
       "1           0                30's   \n",
       "2           0            70 Nigga   \n",
       "3           0               Aight   \n",
       "4           0         At the Door   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [Intro]\\r\\nAyy, ayy\\r\\n\\r\\n[Chorus]\\r\\nOne cho...  \n",
       "1  [Verse 1: Lil Pump]\\r\\nI'ma hit a stain, I'ma ...  \n",
       "2            \\r\\n            Lyrics for this song...  \n",
       "3  [Intro: Lil Pump]\\r\\nYuh, ouu, ouu, ouu, ouu, ...  \n",
       "4  [Intro]\\r\\nOoh, Big Head on the beat\\r\\nLil Pu...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = open('all_lyrics.txt', 'w')\n",
    "for row in data.itertuples():\n",
    "    text = row.lyrics\n",
    "    title = row.title\n",
    "    if text.startswith('     '):\n",
    "        continue\n",
    "    all_lyrics.write(title + '\\n')\n",
    "    all_lyrics.write('********************\\n')\n",
    "    all_lyrics.write(text + '\\n')\n",
    "    all_lyrics.write('********************\\n\\n\\n')\n",
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "all_lyrics = open('all_lyrics.txt', 'r')\n",
    "for line in all_lyrics:\n",
    "    if line.startswith(' '):\n",
    "        line = line.lstrip()\n",
    "    line = line.lower()\n",
    "    if line.startswith('[chorus'):\n",
    "        lines.append('[chorus] \\n')\n",
    "    elif line.startswith('[verse'):\n",
    "        lines.append('[verse] \\n')\n",
    "    elif line.startswith('[hook'):\n",
    "        lines.append('[hook] \\n')\n",
    "    elif line.startswith('[intro'):\n",
    "        lines.append('[intro] \\n')\n",
    "    elif line.startswith('[outro'):\n",
    "        lines.append('[outro] \\n')\n",
    "    elif line.startswith('[bridge'):\n",
    "        lines.append('[bridge] \\n')\n",
    "    elif line.startswith('[interlude'):\n",
    "        lines.append('[interlude] \\n')\n",
    "    elif line.startswith('lyrics for this'):\n",
    "        lines.append('\\n')\n",
    "    else:\n",
    "        lines.append(line)\n",
    "all_lyrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_cleaned = open('all_lyrics_cleaned.txt', 'w')\n",
    "for line in lines:\n",
    "    all_lyrics_cleaned.write(line)\n",
    "all_lyrics_cleaned.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of corpus is now  46584\n"
     ]
    }
   ],
   "source": [
    "# Read in the entire file.\n",
    "f = open('all_lyrics_cleaned.txt')\n",
    "corpus0 = f.read()\n",
    "f.close()\n",
    "\n",
    "# Separate the punctuation from the words, so that words with\n",
    "# punctuation do not get counted as distinct from words without\n",
    "# punctuation.  Same for new line characters.\n",
    "\n",
    "corpus0 = corpus0.replace(',', ' ,')\n",
    "corpus0 = corpus0.replace('(', ' ( ')\n",
    "corpus0 = corpus0.replace(')', ' ) ')\n",
    "#corpus0 = corpus0.replace('[', ' [ ')\n",
    "#corpus0 = corpus0.replace(']', ' ] ')\n",
    "corpus0 = corpus0.replace('.', ' . ')\n",
    "corpus0 = corpus0.replace(';', ' ; ')\n",
    "corpus0 = corpus0.replace(':', ' : ')\n",
    "corpus0 = corpus0.replace('!', ' ! ')\n",
    "corpus0 = corpus0.replace('?', ' ? ')\n",
    "corpus0 = corpus0.replace('********************', ' ******************** ')\n",
    "#corpus0 = corpus0.replace('*', ' * ')\n",
    "corpus0 = corpus0.replace(\"â€™\", '\\'')\n",
    "corpus0 = corpus0.replace(\"\\'\\'\", ' \" ')\n",
    "corpus0 = corpus0.replace('\"', ' \" ')\n",
    "corpus0 = corpus0.replace('\\r\\n', ' \\r\\n ')\n",
    "\n",
    "# Separate the dashes from any words they're attached to.\n",
    "corpus0 = corpus0.replace('-', ' - ')\n",
    "corpus0 = corpus0.replace('\\n', ' \\n ')\n",
    "\n",
    "# Convert the text to lower case.\n",
    "corpus0 = corpus0.lower()\n",
    "\n",
    "# Split the words by spaces; only take the first 500000 words.\n",
    "# This number was chosen based on memory limits and training-time\n",
    "# limitations.\n",
    "corpus1 = corpus0.split(' ')\n",
    "\n",
    "while (corpus1.count('') > 0): \n",
    "    corpus1.remove('')\n",
    "    \n",
    "print('Length of corpus is now ', len(corpus1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2500 different words.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing is done.  Now get the unique words, and encode them.\n",
    "words = sorted(list(set(corpus1)))\n",
    "num_words = len(words)\n",
    "encoding = {w: i for i, w in enumerate(words)}\n",
    "decoding = {i: w for i, w in enumerate(words)}\n",
    "\n",
    "print('We have', num_words, 'different words.')\n",
    "corpus = corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 46534 sentences.\n",
      "Encoding data.\n"
     ]
    }
   ],
   "source": [
    "# Chop up the data into x and y, slice into roughly num_chars\n",
    "# overlapping 'sentences' of length sentence_length.  Encode the\n",
    "# characters.\n",
    "sentence_length = 50\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(0, len(corpus) - sentence_length):\n",
    "    sentence = corpus[i: i + sentence_length]\n",
    "    next_word = corpus[i + sentence_length]\n",
    "    x_data.append([encoding[word] for word in sentence])\n",
    "    y_data.append(encoding[next_word])\n",
    "\n",
    "# good word: phronesis\n",
    "num_sentences = len(x_data)\n",
    "print('We have', len(x_data), 'sentences.')\n",
    "\n",
    "# Create the variables to hold the data as it will be used.\n",
    "x = np.zeros((num_sentences, sentence_length, num_words), dtype = np.bool)\n",
    "y = np.zeros((num_sentences, num_words), dtype = np.bool)\n",
    "\n",
    "# Populate the sentences.\n",
    "print('Encoding data.')\n",
    "for i, sentence in enumerate(x_data):\n",
    "    for t, encoded_word in enumerate(sentence):\n",
    "        x[i, t, encoded_word] = 1\n",
    "    y[i, y_data[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed data.\n"
     ]
    }
   ],
   "source": [
    "# The processing of the data takes a fair amount of time.  Save\n",
    "# the data so we don't have to do this again.  We do this in a\n",
    "# numpy file since the data is large and the shelve can't handle\n",
    "# it.\n",
    "\n",
    "print('Saving processed data.')\n",
    "np.save('x.npy', x)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network.\n"
     ]
    }
   ],
   "source": [
    "print('Building network.')\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(128, input_shape = (sentence_length, num_words)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(kl.Dense(num_words, activation = 'softmax'))\n",
    "optimizer = RMSprop(lr=0.01) # 'sgd'\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fit.\n",
      "Epoch 1/10\n",
      "46534/46534 [==============================] - 104s 2ms/step - loss: 4.3631 - acc: 0.2590\n",
      "Epoch 2/10\n",
      "46534/46534 [==============================] - 102s 2ms/step - loss: 2.9910 - acc: 0.4656\n",
      "Epoch 3/10\n",
      "46534/46534 [==============================] - 102s 2ms/step - loss: 2.4405 - acc: 0.5533\n",
      "Epoch 4/10\n",
      "46534/46534 [==============================] - 102s 2ms/step - loss: 2.1055 - acc: 0.6088\n",
      "Epoch 5/10\n",
      "46534/46534 [==============================] - 102s 2ms/step - loss: 1.8714 - acc: 0.6500\n",
      "Epoch 6/10\n",
      "46534/46534 [==============================] - 102s 2ms/step - loss: 1.6928 - acc: 0.6826\n",
      "Epoch 7/10\n",
      "30976/46534 [==================>...........] - ETA: 34s - loss: 1.4981 - acc: 0.7161"
     ]
    }
   ],
   "source": [
    "# Fit!  Begin elevator music...\n",
    "print('Beginning fit.')\n",
    "fit = model.fit(x, y, epochs = 10, batch_size = 256)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model_50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning fit.\n",
      "Epoch 1/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.4609 - acc: 0.9124\n",
      "Epoch 2/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.4435 - acc: 0.9151\n",
      "Epoch 3/20\n",
      "46559/46559 [==============================] - 47s 999us/step - loss: 0.4357 - acc: 0.9157\n",
      "Epoch 4/20\n",
      "46559/46559 [==============================] - 47s 999us/step - loss: 0.4125 - acc: 0.9194\n",
      "Epoch 5/20\n",
      "46559/46559 [==============================] - 47s 1000us/step - loss: 0.3986 - acc: 0.9226\n",
      "Epoch 6/20\n",
      "46559/46559 [==============================] - 46s 998us/step - loss: 0.3883 - acc: 0.9231\n",
      "Epoch 7/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3735 - acc: 0.9257\n",
      "Epoch 8/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3689 - acc: 0.9258\n",
      "Epoch 9/20\n",
      "46559/46559 [==============================] - 47s 1000us/step - loss: 0.3553 - acc: 0.9277\n",
      "Epoch 10/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3385 - acc: 0.9307\n",
      "Epoch 11/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3316 - acc: 0.9329\n",
      "Epoch 12/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3237 - acc: 0.9324\n",
      "Epoch 13/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.3101 - acc: 0.9354\n",
      "Epoch 14/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2976 - acc: 0.9390\n",
      "Epoch 15/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2920 - acc: 0.9377\n",
      "Epoch 16/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2878 - acc: 0.9385\n",
      "Epoch 17/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2746 - acc: 0.9416\n",
      "Epoch 18/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2733 - acc: 0.9416\n",
      "Epoch 19/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2675 - acc: 0.9425\n",
      "Epoch 20/20\n",
      "46559/46559 [==============================] - 47s 1ms/step - loss: 0.2629 - acc: 0.9431\n"
     ]
    }
   ],
   "source": [
    "# Fit!  Begin elevator music...\n",
    "print('Beginning fit.')\n",
    "fit = model.fit(x, y, epochs = 20, batch_size = 256)\n",
    "\n",
    "# Save the model so that we can use it as a starting point.\n",
    "model.save('model_50.h5')\n",
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This piece of code will load the saved model from the file and generate a song from the initial seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model file.\n",
      "Generated lyrics: \n",
      "\n",
      "the door \n",
      " i got the kitchen i spent two bust on a whip it i never fuckin' \n",
      " i got a big . and ya \n",
      " ayy , ayy , yeah , lil pump , yeah , ouu , yeah , huh \n",
      " brr , huh \n",
      " i'm in the bitch , ay , ooh , lil pump , yeah , [chorus] \n",
      " hold up on pop out \n",
      " ******************** \n",
      " \n",
      " \n",
      " dr . phil \n",
      " ******************** \n",
      " racks on racks \n",
      " \n",
      " [chorus] \n",
      " yeah , multi shit ( ooh , ooh ) \n",
      " if you got the lot of bitches , designer the bust down ( chyeah , chyeah ) \n",
      " i'm the youngest flexer ( what ) , i'm the youngest flexer \n",
      " \n",
      " [verse] \n",
      " i just left the youngest flexer \n",
      " bitch , i just obama \n",
      " ******************** \n",
      " [intro] \n",
      " lil pump \n",
      " ******************** \n",
      " [intro] \n",
      " lil pump \n",
      " ayy , ayy , ayy \n",
      " oh my god , ronny \n",
      " vroom \n",
      " \n",
      " [chorus] \n",
      " vroom vroom , vroom vroom vroom vroom ( vroom ) \n",
      " bitch , convertible coupe ( yeah ) \n",
      " she gon' flash her titties ( flash 'em ) , out of the roof ( yeah ) \n",
      " scoot scoot , scoot scoot scoot scoot ( scoot , scoot ) \n",
      " she gon' fuck on the crew \n",
      " who who , who , who is you ? ( who ? ) \n",
      " i ain't heard of you \n",
      " vroom vroom , vroom vroom vroom vroom ( vroom ) \n",
      " bitch , convertible coupes \n",
      " vroom , vroom vroom vroom vroom ( vroom ) \n",
      " bitch , convertible coupes \n",
      " i'ma hop out and just shoot you in front of your boo \n",
      " i got so much guns on me ( bah ) , i'm in a hotel room ( bah , bah , bah , bah ) \n",
      " \n",
      " [verse] \n",
      " you gon' rob me ? hahaha \n",
      " bitch , i'm laughing at you ( bitch ) \n",
      " woo , woo , [chorus] , i flex like he a door , ouu ( i got a big . 30 \n",
      " \n",
      " [chorus] \n",
      " i got fast cars , bad bitches and designer clothes \n",
      " couple thousand on my wrist and my neck is on froze \n",
      " spanish bitches' butt naked and they twerkin' on the stove \n",
      " too much racks in my pocket that my wallet can't fold \n",
      " i got fast cars , bad bitches and designer clothes \n",
      " i got fast cars , bad bitches and designer clothes \n",
      " couple thousand on my wrist and my neck is on froze \n",
      " too much racks in my pocket that my wallet can't fold \n",
      " ******************** \n",
      " \n",
      " \n",
      " designer ( brr , ayy , chyeah , ayy , ayy , ayy ) \n",
      " i'm gon' got that \n",
      " came in a foreign ( ooh ) \n",
      " ouu , i just love \n",
      " no way , \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras.models as km\n",
    "import shelve\n",
    "import random\n",
    "\n",
    "modelfile = 'model_25.h5'\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "# Get the model.\n",
    "print('Reading model file.')\n",
    "model = km.load_model(modelfile)\n",
    "\n",
    "# Get the meta-data.\n",
    "\n",
    "sentence_length = 25\n",
    "num_words = 2500\n",
    "\n",
    "\n",
    "# Randomly choose 50 words from the dictionary of words as our\n",
    "# starting sentence.\n",
    "seed = []\n",
    "for i in range(sentence_length):\n",
    "    seed.append(decoding[random.randint(0, num_words - 1)])\n",
    "\n",
    "\n",
    "# Encode the seed sentence.\n",
    "x = np.zeros((1, sentence_length, num_words), dtype = np.bool)\n",
    "for i, w in enumerate(seed):\n",
    "    x[0, i, encoding[w]] = 1\n",
    "\n",
    "text = ''\n",
    "\n",
    "# Run the seed sentence through the model.  Add the output to the\n",
    "# generated text.  Take the output and append it to the seed sentence\n",
    "# and remove the first word from the seed sentence.  Then repeat until\n",
    "# you've generated as many words as you like.\n",
    "for i in range(500):\n",
    "\n",
    "    # Get the most-probably next word.\n",
    "    pred = np.argmax(model.predict(x, verbose = 0))\n",
    "\n",
    "    # Add it to the generated text.\n",
    "    text += decoding[pred] + ' '\n",
    "\n",
    "    # Encode the next word.\n",
    "    next_word = np.zeros((1, 1, num_words), dtype = np.bool)\n",
    "    next_word[0, 0, pred] = 1\n",
    "\n",
    "    # Concatenate the next word to the seed sentence, but leave off\n",
    "    # the first element so that the length stays the same.\n",
    "    x = np.concatenate((x[:, 1:, :], next_word), axis = 1)\n",
    "\n",
    "    \n",
    "# Print out the generated text.\n",
    "print(\"Generated lyrics: \\n\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
